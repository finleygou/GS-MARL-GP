# scenarios.py
# This file contains the Scenarios class with hardcoded data from the provided CSV, rounded to 2 decimal places, for 9 agents.

class Scenarios:
    data = {
        0: {
            'obstacles': [(2.07, -1.23), (0.74, 2.40), (-2.16, 2.60), (-2.13, 0.66), (-0.85, -0.39), (2.35, 0.58), (2.50, -1.54), (-2.38, 2.32), (-2.24, -2.22)],
            'egos': [(-1.52, 1.78), (2.01, 0.31), (2.56, 0.41), (-1.39, 0.37), (-0.08, 1.43), (-1.90, 0.79), (-0.60, -2.42), (2.74, -3.01), (-1.25, -1.44)],
            'targets': [(1.95, -0.41), (0.44, -0.55), (-1.41, 1.11), (2.55, 1.31), (2.09, 1.27), (-2.20, -0.50), (2.10, 0.32), (-0.03, -0.93), (1.51, 1.54)],
        },
        1: {
            'obstacles': [(-0.17, 1.51), (-0.58, -2.37), (-2.20, 2.17), (-1.43, -2.69), (-2.50, 0.03), (-1.83, 0.67), (2.60, -2.48), (0.06, 2.39), (-2.65, -0.85)],
            'egos': [(1.62, -2.30), (-1.61, -0.05), (-2.29, -2.37), (0.88, 2.79), (-1.63, -3.04), (2.21, 0.21), (-1.87, -2.06), (1.77, -3.29), (2.08, -2.73)],
            'targets': [(2.37, 1.07), (1.04, -0.40), (1.79, -0.21), (2.57, -0.05), (1.28, -1.03), (-0.92, -0.73), (-0.69, 1.57), (2.29, -2.59), (-1.84, 1.33)],
        },
        2: {
            'obstacles': [(-0.74, -1.35), (-0.20, 1.16), (-2.05, 2.51), (-1.01, -2.60), (-0.93, 1.90), (1.04, 0.04), (-0.08, -1.64), (-0.49, 1.31), (-1.59, 2.55)],
            'egos': [(-3.33, -1.54), (-1.75, 0.79), (1.99, 2.81), (0.63, -2.38), (-1.64, 3.44), (-2.96, -1.12), (-1.38, -2.10), (-1.17, 1.79), (0.73, -0.77)],
            'targets': [(1.16, -0.20), (2.00, -2.38), (-2.15, -1.26), (-0.47, -1.85), (0.74, -2.22), (-1.84, -1.47), (0.16, -1.85), (2.72, 2.00), (-1.96, -2.53)],
        },
        3: {
            'obstacles': [(-1.82, 2.69), (-0.90, -1.70), (-2.66, 0.91), (1.73, -2.70), (0.44, 1.06), (-1.38, 2.09), (-2.48, -2.48), (-0.28, -1.33), (-1.24, -1.73)],
            'egos': [(-1.46, 1.00), (2.15, 2.52), (0.83, -2.99), (0.84, -0.39), (2.62, 2.72), (2.17, -1.64), (1.13, 2.25), (-2.12, -1.12), (-3.38, -2.77)],
            'targets': [(0.51, -2.11), (1.58, -1.72), (0.37, 1.37), (2.38, -2.03), (1.96, 1.19), (1.27, -2.13), (-2.22, -2.24), (-0.44, -0.99), (0.64, 1.40)],
        },
        4: {
            'obstacles': [(1.71, -0.66), (0.99, 1.97), (-0.32, -0.49), (-0.07, -2.41), (-1.06, 0.09), (1.47, -1.96), (2.31, 0.96), (1.07, -2.60), (2.34, -1.50)],
            'egos': [(-1.41, 0.57), (3.25, 0.87), (-1.85, 0.57), (-2.76, -0.51), (-2.14, -2.76), (-0.56, -2.37), (-2.42, -0.74), (-2.67, -2.03), (2.41, -2.68)],
            'targets': [(2.37, -0.78), (-2.14, 0.37), (0.54, -0.95), (0.90, -1.69), (0.74, -2.42), (-2.22, -0.80), (1.31, -2.06), (-0.75, 2.23), (0.06, 0.85)],
        },
        # 5: {
        #     'obstacles': [(1.74, 1.51), (-1.56, -0.80), (0.59, -1.56), (-0.81, 1.39), (-2.64, 0.97), (-2.06, -2.00), (-0.44, -2.37), (2.60, -2.36), (-0.55, 0.61)],
        #     'egos': [(1.26, -0.89), (-0.85, 1.85), (-0.36, -1.85), (0.92, -2.07), (-1.69, -3.17), (-3.37, -1.24), (3.04, 0.12), (2.25, 2.44), (-1.81, -2.64)],
        #     'targets': [(-2.73, 2.30), (0.01, 1.85), (-0.08, -2.34), (-0.52, -0.33), (-2.68, -0.59), (2.69, -2.03), (0.53, -1.09), (2.63, 2.72), (-1.45, -2.35)],
        # },
        # 6: {
        #     'obstacles': [(0.04, -1.06), (1.07, -2.24), (0.84, -0.57), (-2.06, -1.04), (1.47, 2.26), (-2.62, -0.11), (2.07, -2.08), (0.78, -2.67), (-0.65, -1.15)],
        #     'egos': [(-0.88, 3.39), (-2.21, -1.28), (2.28, -2.55), (-2.78, -2.57), (-0.32, 3.23), (-0.30, -1.47), (2.60, -1.39), (-0.61, -2.97), (0.80, -1.44)],
        #     'targets': [(-0.71, 1.76), (0.62, 2.47), (-2.66, -2.14), (-1.65, -1.38), (-1.21, 1.23), (2.29, -2.38), (-2.64, -0.52), (-1.85, -0.59), (-0.72, -0.16)],
        # },
        # 7: {
        #     'obstacles': [(-0.81, 1.10), (-0.31, 2.76), (-2.09, 1.31), (1.93, 2.11), (-1.68, 0.91), (-0.63, -1.85), (-2.70, -0.78), (0.63, -1.23), (-0.71, 2.37)],
        #     'egos': [(-0.04, 1.70), (-1.96, -0.01), (0.86, 2.15), (0.34, 2.07), (1.44, 0.30), (-0.82, -2.03), (3.07, 1.57), (0.27, 0.66), (2.39, 0.12)],
        #     'targets': [(-1.04, 0.24), (-1.20, 2.57), (0.44, -0.10), (-1.59, 0.02), (2.39, 0.27), (0.66, 1.82), (-1.58, -0.84), (-0.98, -0.23), (-0.30, 0.31)],
        # },
        # 8: {
        #     'obstacles': [(-1.13, 1.85), (1.22, -0.69), (2.12, -2.72), (2.30, 1.21), (-1.17, -1.50), (-2.69, 2.69), (-0.41, 1.26), (-0.03, -1.98), (0.77, -1.07)],
        #     'egos': [(3.01, -2.22), (0.81, -1.68), (-2.05, -1.93), (-1.69, 0.73), (2.33, 3.04), (-1.09, 0.17), (-2.14, -2.81), (3.33, 3.23), (-2.59, -2.00)],
        #     'targets': [(-2.16, 0.34), (0.56, 0.49), (-1.44, 2.49), (0.13, 0.22), (-0.22, -1.14), (2.75, 0.26), (2.60, -2.52), (-2.06, 2.02), (0.02, 2.17)],
        # },
        # 9: {
        #     'obstacles': [(2.66, -1.48), (2.46, -2.69), (-1.55, -2.24), (0.04, -2.05), (0.26, -1.51), (-1.98, 0.71), (1.17, 0.16), (-0.05, 1.39), (2.15, -0.09)],
        #     'egos': [(2.51, -0.25), (0.70, -0.57), (1.88, -2.59), (-1.12, 1.32), (1.38, -0.03), (-1.65, 1.96), (0.43, -3.31), (-1.38, -2.46), (1.02, -0.18)],
        #     'targets': [(-0.39, 1.38), (1.50, -1.30), (1.62, 2.04), (-2.10, -1.25), (-1.95, 2.02), (2.27, -0.82), (1.58, 0.81), (-0.03, -1.54), (-0.84, -1.75)],
        # },
    }

# Usage in your main program:
# import numpy as np
# from scenarios import Scenarios
#
# In reset_world:
# sid = np.random.randint(0, 10)
# scenario = Scenarios.data[sid]
#
# # Assign obstacles
# for i, (x, y) in enumerate(scenario['obstacles']):
#     world.obstacles[i].state.p_pos = np.array([x, y])
#     world.obstacles[i].state.p_vel = np.zeros(world.dim_p)
#
# # Assign egos
# for i, (x, y) in enumerate(scenario['egos']):
#     world.egos[i].state.p_pos = np.array([x, y])
#     world.egos[i].state.p_vel = np.zeros(world.dim_p)
#     # Goal is target position (assuming targets correspond to egos by index)
#     tx, ty = scenario['targets'][i]
#     world.egos[i].goal = np.array([tx, ty])
#
# # Assign targets
# for i, (x, y) in enumerate(scenario['targets']):
#     world.targets[i].state.p_pos = np.array([x, y])
#     world.targets[i].state.p_vel = np.zeros(world.dim_p)